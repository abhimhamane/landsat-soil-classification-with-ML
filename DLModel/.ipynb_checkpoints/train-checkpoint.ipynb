{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "\n",
    "from .network import NeuralNetwork\n",
    "from .optimizers import Optimizer\n",
    "from .utility.np_utility import permute_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    '''\n",
    "    Just a list of layers that runs forwards and backwards\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 net: NeuralNetwork,\n",
    "                 optim: Optimizer) -> None:\n",
    "        self.net = net\n",
    "        self.optim = optim\n",
    "        self.best_loss = 1e9\n",
    "        setattr(self.optim, 'net', self.net)\n",
    "\n",
    "    def fit(self, X_train: ndarray, y_train: ndarray,\n",
    "            X_test: ndarray, y_test: ndarray,\n",
    "            epochs: int=100,\n",
    "            eval_every: int=10,\n",
    "            batch_size: int=32,\n",
    "            seed: int = 1,\n",
    "            single_output: bool = False,\n",
    "            restart: bool = True,\n",
    "            early_stopping: bool = True,\n",
    "            conv_testing: bool = False)-> None:\n",
    "\n",
    "        setattr(self.optim, 'max_epochs', epochs)\n",
    "        self.optim._setup_decay()\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        if restart:\n",
    "            for layer in self.net.layers:\n",
    "                layer.first = True\n",
    "\n",
    "            self.best_loss = 1e9\n",
    "\n",
    "        for e in range(epochs):\n",
    "\n",
    "            if (e+1) % eval_every == 0:\n",
    "\n",
    "                last_model = deepcopy(self.net)\n",
    "\n",
    "            X_train, y_train = permute_data(X_train, y_train)\n",
    "\n",
    "            batch_generator = self.generate_batches(X_train, y_train,\n",
    "                                                    batch_size)\n",
    "\n",
    "            for ii, (X_batch, y_batch) in enumerate(batch_generator):\n",
    "\n",
    "                self.net.train_batch(X_batch, y_batch)\n",
    "\n",
    "                self.optim.step()\n",
    "\n",
    "                if conv_testing:\n",
    "                    if ii % 10 == 0:\n",
    "                        test_preds = self.net.forward(X_batch)\n",
    "                        batch_loss = self.net.loss.forward(test_preds, y_batch)\n",
    "                        print(\"batch\",\n",
    "                              ii,\n",
    "                              \"loss\",\n",
    "                              batch_loss)\n",
    "\n",
    "                    if ii % 100 == 0 and ii > 0:\n",
    "                        print(\"Validation accuracy after\", ii, \"batches is\",\n",
    "                        f'''{np.equal(np.argmax(self.net.forward(X_test), axis=1),\n",
    "                        np.argmax(y_test, axis=1)).sum() * 100.0 / X_test.shape[0]:.2f}%''')\n",
    "\n",
    "            if (e+1) % eval_every == 0:\n",
    "\n",
    "                test_preds = self.net.forward(X_test)\n",
    "                loss = self.net.loss.forward(test_preds, y_test)\n",
    "\n",
    "                if early_stopping:\n",
    "                    if loss < self.best_loss:\n",
    "                        print(f\"Validation loss after {e+1} epochs is {loss:.3f}\")\n",
    "                        self.best_loss = loss\n",
    "                    else:\n",
    "                        print()\n",
    "                        print(f\"Loss increased after epoch {e+1}, final loss was {self.best_loss:.3f},\",\n",
    "                              f\"\\nusing the model from epoch {e+1-eval_every}\")\n",
    "                        self.net = last_model\n",
    "                        # ensure self.optim is still updating self.net\n",
    "                        setattr(self.optim, 'net', self.net)\n",
    "                        break\n",
    "                else:\n",
    "                    print(f\"Validation loss after {e+1} epochs is {loss:.3f}\")\n",
    "\n",
    "            if self.optim.final_lr:\n",
    "                self.optim._decay_lr()\n",
    "\n",
    "\n",
    "    def generate_batches(self,\n",
    "                         X: ndarray,\n",
    "                         y: ndarray,\n",
    "                         size: int = 32) -> Tuple[ndarray]:\n",
    "\n",
    "        assert X.shape[0] == y.shape[0], \\\n",
    "        '''\n",
    "        features and target must have the same number of rows, instead\n",
    "        features has {0} and target has {1}\n",
    "        '''.format(X.shape[0], y.shape[0])\n",
    "\n",
    "        N = X.shape[0]\n",
    "\n",
    "        for ii in range(0, N, size):\n",
    "            X_batch, y_batch = X[ii:ii+size], y[ii:ii+size]\n",
    "\n",
    "            yield X_batch, y_batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
